{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Modoap_segmentation_entrainement_V2.ipynb","provenance":[{"file_id":"1bj6N7vic4jU1gnv_cf462SelhdZ2wuGO","timestamp":1600433492838}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zUR53o2R7IxX","colab_type":"text"},"source":["**Segmentation d'images dans les documents historiques**\n","\n","\n","**Script d'auto apprentissage**\n","\n","Ce script permet d'entraîner l'algorithme Mask-RCNN à la segmentation d'objets sur ses propres données d'entraînement. \n","Il requiert un corpus d'entraînement : un fichier zip composé de deux dossiers \"train\" et \"val\" contenant chacun les images et leur fichier d'annotation nommé *via_region_data.json*\n","\n","**Ce script doit impérativement être lancé dans un environnement GPU : Runtime -> Change runtime type -> GPU**"]},{"cell_type":"markdown","metadata":{"id":"nj9N8jUV9M_l","colab_type":"text"},"source":["**1. Téléchargement de l'algorithme et installation des pré-requis**"]},{"cell_type":"code","metadata":{"id":"_oeOCtcENZlL","colab_type":"code","colab":{}},"source":["import os\n","%cd\n","if not os.path.exists(\"/root/Mask_RCNN\"):\n","\n","  !git clone --quiet https://github.com/matterport/Mask_RCNN.git\n","  %cd /root/Mask_RCNN\n","  !pip install -q PyDrive\n","  !pip install -r requirements.txt\n","  !python setup.py install\n","  !cp ~/Mask_RCNN/samples/balloon/balloon.py ./illustration.py\n","  !sed -i -- 's/balloon/illustration/g' illustration.py\n","  !sed -i -- 's/Balloon/Illustration/g' illustration.py\n","# !sed -i -- 's/epochs=30/epochs=40/g' illustration.py # Spécifier le nombre d'époques ici\n","\n","  if not os.path.exists(\"/root/Mask_RCNN/weights\"):\n","    os.makedirs('weights')\n","  if not os.path.exists(\"/root/Mask_RCNN/dataset\"):\n","    os.makedirs('dataset')\n","else : print(\"L'algorithme est déjà téléchargé\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p_AWP4MA9fAa","colab_type":"text"},"source":["**2. Spécification des versions de TensorFlow et Keras**"]},{"cell_type":"code","metadata":{"id":"ptiAfqrfN82N","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","!pip install q keras==2.1.5\n","!pip install q keras==2.1.5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w8dL8VUMWhUw","colab_type":"text"},"source":["**3. Importation du corpus d'entraînement**\n","\n","- **Pour un corpus annoté avec VIA :**\n","\n","Importer un fichier zip constitué de cette architecture :\n","\n","(le nom et le format des images sont libres)\n","\n","(le fichier via_region_data.json est obtenu dans VIA par Annotation -> Export Annotations (as json)\n","\n","\n","```\n","  train\n","  img1.jpg\n","  img2.jpg\n","  ...\n","  img100.jpg\n","  via_region_data.json\n","val\n","  img101.jpg\n","  img102.jpg\n","  ...\n","  img120.jpg\n","  via_region_data.json\n","```\n","\n","- **Pour un corpus annoté avec Annotate :**\n","\n","un fichier zip constitué de cette architecture:\n","\n","Le nom et le format des images sont libres\n","\n","Le fichier annotate_region_data.csv est obtenu dans Annotate par View and Export results of annotation -> Annotations -> Export CSV -> Use Coma Separator\n","\n","Testé avec Annotate 1.7\n","\n","\n","\n","```\n","  train\n","  img1.jpg\n","  img2.jpg\n","  ...\n","  img100.jpg\n","  annotate_region_data.csv\n","val\n","  img101.jpg\n","  img102.jpg\n","  ...\n","  img120.jpg\n","  annotate_region_data.csv\n","```\n","**Trois possibilités au choix pour importer le corpus :**\n","\n","1.   Importer le corpus d'entraînement fourni sur le github modoap-seg (entraîné sur 120 pages de la revue Droits Et Libertés (noir et blanc), et 30 époques)\n","2.   Importer son fichier Zip depuis son Google Drive (nécessite une authentification Google et le partage de son fichier) - téléchargement rapide\n","3.   Importer son fichier Zip depuis son disque local - téléchargement plus long"]},{"cell_type":"markdown","metadata":{"id":"jSDHimRk_zpN","colab_type":"text"},"source":["**3.1 Importer le corpus d'entraînement fourni sur le github modoap-seg**"]},{"cell_type":"code","metadata":{"id":"mn4zkbPOOGzG","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/dataset/\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Datasets/exemple_entrainement_droitsetlibertes/corpus_train_val.7z.001\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Datasets/exemple_entrainement_droitsetlibertes/corpus_train_val.7z.002\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Datasets/exemple_entrainement_droitsetlibertes/corpus_train_val.7z.003\n","\n","!7z x /root/Mask_RCNN/dataset/corpus_train_val.7z.001\n","os.remove(\"/root/Mask_RCNN/dataset/corpus_train_val.7z.001\")\n","os.remove(\"/root/Mask_RCNN/dataset/corpus_train_val.7z.002\")\n","os.remove(\"/root/Mask_RCNN/dataset/corpus_train_val.7z.003\")\n","\n","!7z x /root/Mask_RCNN/dataset/corpus_entrainement_DL.zip\n","os.remove(\"/root/Mask_RCNN/dataset/corpus_entrainement_DL.zip\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xl85NkqHAJxf","colab_type":"text"},"source":["**3.2 Importer un fichier Zip depuis son Google Drive**\n","\n","Cette méthode nécessite de copier le lien partageable de son fichier sur son Google Drive (exemple : 1nWoZIRsw9Kx7CriJ3OgB436PPllV7veC), et de se connecter à son compte via le code de vérification fourni par Google."]},{"cell_type":"code","metadata":{"id":"ylHTJD2LPedZ","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/dataset\n","fileId = input(\"Entrez le lien partageable du fichier \")\n","\n","from zipfile import ZipFile\n","from shutil import copy\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","fileName = fileId + '.zip'\n","downloaded = drive.CreateFile({'id': fileId})\n","downloaded.GetContentFile(fileName)\n","ds = ZipFile(fileName)\n","ds.extractall()\n","os.remove(fileName)\n","print('Fichier extrait ' + fileName)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAk39R81BQvM","colab_type":"text"},"source":["**3.3 Importer un fichier zip depuis son disque local**\n","\n","Lancer la cellule et cliquer sur \"Browse\". Le téléchargement est plus long."]},{"cell_type":"code","metadata":{"id":"UcIUjZCVPihT","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/dataset\n","from google.colab import files\n","corpus = files.upload()\n","fichier = list(corpus.keys())[0]\n","!7z x $fichier \n","os.remove(fichier)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Hfc_7E1FUvMX","colab_type":"text"},"source":["**3.4 Traduction des annotations réalisées avec VIA** (nécessaire)\n","\n","Rappel : les fichiers d'annotations VIA dans les dossiers \"train\" et \"val\" doivent tous deux être nommés \"via_region_data.json\"\n","\n","Cette cellule transforme les annotations rectangulaires en polygones à 4 coordonnées, traitables par l'algorithme"]},{"cell_type":"code","metadata":{"id":"REgCpCfrSlys","colab_type":"code","colab":{}},"source":["import os\n","import json\n","\n","\n","def traductionVIA(viajson):\n","  annotations = json.load(open(viajson))\n","  if \"_via_settings\" in annotations.keys() :\n","      annotations_new = {}\n","      for image in annotations[\"_via_img_metadata\"]:\n","          valeur_image = annotations[\"_via_img_metadata\"][image]\n","          nom = image\n","          annotations_new[nom] = valeur_image\n","          for i in range(len(annotations[\"_via_img_metadata\"][image][\"regions\"])) :\n","              if annotations[\"_via_img_metadata\"][image][\"regions\"][i][\"shape_attributes\"][\"name\"] == \"rect\":\n","\n","                  x = annotations[\"_via_img_metadata\"][image][\"regions\"][i][\"shape_attributes\"][\"x\"]\n","                  y = annotations[\"_via_img_metadata\"][image][\"regions\"][i][\"shape_attributes\"][\"y\"]\n","                  width = annotations[\"_via_img_metadata\"][image][\"regions\"][i][\"shape_attributes\"][\"width\"]\n","                  height = annotations[\"_via_img_metadata\"][image][\"regions\"][i][\"shape_attributes\"][\"height\"]\n","\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"all_points_x\"] = [x, x+width, x+width, x]\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"all_points_y\"] = [y, y, y+height, y+height]\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"name\"] = \"polygon\"\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"y\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"x\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"width\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"height\"]\n","\n","  else :\n","      annotations_new = annotations\n","      for image in annotations :\n","          for i in range(len(annotations[image][\"regions\"])) :\n","              if annotations[image][\"regions\"][i][\"shape_attributes\"][\"name\"] == \"rect\":\n","                  x = annotations[image][\"regions\"][i][\"shape_attributes\"][\"x\"]\n","                  y = annotations[image][\"regions\"][i][\"shape_attributes\"][\"y\"]\n","                  width = annotations[image][\"regions\"][i][\"shape_attributes\"][\"width\"]\n","                  height = annotations[image][\"regions\"][i][\"shape_attributes\"][\"height\"]\n","\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"all_points_x\"] = [x, x+width, x+width, x]\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"all_points_y\"] = [y, y, y+height, y+height]\n","                  annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"name\"] = \"polygon\"\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"y\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"x\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"width\"]\n","                  del annotations_new[image][\"regions\"][i][\"shape_attributes\"][\"height\"]\n","              \n","  with open('via_region_data.json', 'w') as json_file:\n","    json.dump(annotations_new, json_file)\n","    \n","%cd /root/Mask_RCNN/dataset/train\n","traductionVIA(\"via_region_data.json\")\n","\n","%cd /root/Mask_RCNN/dataset/val\n","traductionVIA(\"via_region_data.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6efPqsshW5b6","colab_type":"text"},"source":["**3.5 Traduction des annotations réalisées avec Annotate** (necessaire)\n","\n","Rappel : les fichiers d'annotations Annotate dans les dossiers \"train\" et \"val\" doivent tous deux être nommés \"annotate_region_data.csv\""]},{"cell_type":"code","metadata":{"id":"JqxnM6ooXNq1","colab_type":"code","colab":{}},"source":["import os \n","import pandas as pd\n","\n","def traductionANNOTATE(annotations_csv):\n","\n","  annotationz_new = {}\n","  annotationz = pd.read_csv(annotations_csv).sort_values('File')\n","\n","  for index, row in annotationz.iterrows() :\n","    filename = row[\"File\"]\n","    size = \"\"\n","    regions = {}\n","    x = int(row[\"X\"])\n","    y = int(row[\"Y\"])\n","    w = int(row[\"W\"])\n","    h = int(row[\"H\"])\n","    all_points_x = [x, x+w, x+w, x]\n","    all_points_y = [y, y, y+h, y+h]\n","      \n","    if filename not in annotationz_new.keys(): \n","      annotationz_new[filename] = {\"filename\":filename, \"size\":size,\"regions\":{0:{\"shape_attributes\":{\"name\":\"polygon\", \"all_points_x\":all_points_x,\"all_points_y\":all_points_y}, \"region_attributes\":{}}}, \"file_attributes\":{}}\n","      \n","    else :\n","      i = max(annotationz_new[filename][\"regions\"].keys()) + 1\n","      annotationz_new[filename][\"regions\"][i] = {\"shape_attributes\":{\"name\":\"polygon\", \"all_points_x\":all_points_x,\"all_points_y\":all_points_y}, \"region_attributes\":{}}\n","\n","  with open('via_region_data.json', 'w') as json_file:\n","    json.dump(annotationz_new, json_file)\n","      \n","%cd /root/Mask_RCNN/dataset/train\n","traductionANNOTATE(\"annotate_region_data.csv\")\n","\n","%cd /root/Mask_RCNN/dataset/val\n","traductionANNOTATE(\"annotate_region_data.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KwUCh_B1Bmuk","colab_type":"text"},"source":["**4. Préparation et configuration de l'algorithme**"]},{"cell_type":"code","metadata":{"id":"otF-mtnRPvlU","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/\n","\n","import os\n","import sys\n","import random\n","import math\n","import numpy as np\n","import skimage.io\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import glob\n","\n","ROOT_DIR = os.path.abspath(\"/\")\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","sys.path.append(ROOT_DIR)  \n","from mrcnn import utils\n","import mrcnn.model as modellib\n","from mrcnn import visualize\n","import illustration\n","\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"dataset\")\n","\n","config = illustration.IllustrationConfig()\n","\n","class InferenceConfig(config.__class__):\n","    GPU_COUNT = 1\n","    IMAGES_PER_GPU = 1\n","\n","config = InferenceConfig()\n","config.display()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9g0ZukviUp7q","colab_type":"text"},"source":["**Téléchargement des poids générés sur Droits et Libertés depuis Github**\n","\n","Télécharge le fichier dans /root/Mask_RCNN/weights/mask_rcnn_illustration_0030.h5"]},{"cell_type":"code","metadata":{"id":"ZcZyJMZ1UpKS","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/weights\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Poids/poidsDL.7z.001\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Poids/poidsDL.7z.002\n","!wget https://github.com/cyril521/modoap-seg/raw/master/Poids/poidsDL.7z.003\n","!7z x /root/Mask_RCNN/weights/poidsDL.7z.001\n","os.rename(\"mask_rcnn_illustration_0030.h5\", \"Poids_Droits_Libertes_120p_30ep.h5\")\n","os.remove(\"/root/Mask_RCNN/weights/poidsDL.7z.001\")\n","os.remove(\"/root/Mask_RCNN/weights/poidsDL.7z.002\")\n","os.remove(\"/root/Mask_RCNN/weights/poidsDL.7z.003\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uFa5GYB3CDbH","colab_type":"text"},"source":["**5. Lancement de l'entraînement**\n","\n","L'entraînement peut prendre plusieurs heures en fonction du nombre d'époques choisi. Le résultat est un fichier de poids .h5 sauvegardé dans */root/Mask_RCNN/weights/illustration* (seul le dernier fichier h5 généré sera réutilisé par la suite)\n","\n","Le paramètre --weights= permet de spécifier les poids initiaux à utiliser pour l'entraînement. Les valeurs possibles sont COCO, IMAGENET ou \"/chemin/vers/fichier.h5\"\n","\n","La cellule est remplie par défaut avec le chemin vers les poids Droits Et Libertés téléchargés dans la cellule précédente."]},{"cell_type":"code","metadata":{"id":"tPLBPo9pO3i0","colab_type":"code","colab":{}},"source":["%cd /root/Mask_RCNN/\n","!python illustration.py train --dataset=dataset/ --weights=\"/root/Mask_RCNN/weights/Poids_Droits_Libertes_120p_30ep.h5\" --log=\"/root/Mask_RCNN/weights\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iHMaBgq9DJLO","colab_type":"text"},"source":["**6.1 Téléchargement des poids générés vers le disque dur**"]},{"cell_type":"code","metadata":{"id":"PFA0NgbxPIFK","colab_type":"code","colab":{}},"source":["from google.colab import files\n","listepoids = [file for file in sorted(glob.glob(\"/root/Mask_RCNN/weights/*/*.h5\"))]\n","if len(listepoids) == 0 :\n","    print(\"Aucun poids généré\")\n","else : \n","  poids = listepoids[-1]\n","  files.download(poids)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"68JUBNb-DZVT","colab_type":"text"},"source":["**6.2 Téléchargement des poids générés vers un Google Drive**\n","\n","Nécessite de connecter un compte Google Drive. Le fichier poids est copié à la racine du Drive."]},{"cell_type":"code","metadata":{"id":"lrdHXaF0TaLi","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","if not os.path.exists(\"/content/gdrive\"): \n","  drive.mount('/content/gdrive') \n","%cd /content/gdrive/My Drive\n","\n","listepoids = [file for file in sorted(glob.glob(\"/root/Mask_RCNN/weights/*/*.h5\"))]\n","if len(listepoids) == 0 :\n","    print(\"Aucun poids généré\")\n","else : \n","  poids = listepoids[-1]\n","  !cp $poids ./\n","  print(\"Le poids a été copié sur le Drive\")"],"execution_count":null,"outputs":[]}]}